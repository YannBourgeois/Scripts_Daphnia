### Remove remaining adapters with Trimmomatic, v0.33. Scripts executed in UNIX shell.
mkdir untrimmed
mv *fq.gz untrimmed
for i in ./untrimmed/*.fq.gz
do java -Xmx5G -Xmx5G -jar ./Trimmomatic-0.33/trimmomatic-0.33.jar SE -phred33 $i trimmed_$i ILLUMINACLIP:./Trimmomatic-0.33/adapters/TruSeq2-SE.fa:2:30:10
done

### Index reference genome (Zosterops.fsa)
#If multiline fasta, use this awk script so each scaffold consists of two lines (header+sequence)
# awk '/^>/ {printf("\n%s\n",$0);next; } { printf("%s",$0);}  END {printf("\n");}' < file_to_split.fsa > file_splitted.fsa
bwa index Zosterops.fsa

### Perform alignment with BWA MEM (ALN is now deprecated)
##For Cornell's GBS data (single end sequencing)

for i in *.fq.gz
do bwa mem Zosterops_genome.fsa -t 8  $i -M | samtools view -q 20 -bS - | samtools sort -  $i
done

#Note: If you have an access to a cluster, you can submit one job for each of the N alignments like this:
for i in *.fq.gz
do echo "bwa mem Zosterops_genome.fsa -t 8"  $i "-M | samtools view -q 20 -bS - | samtools sort -"  $i >> command_file
done
#Split the previous file in individual jobs and submit them
split -l1 command_file alignment.sh
for i in alignment.sh*
do qsub $i
done


## For paired-end sequencing (Shotgun sequencing + Pooled RAD-sequencing data). Assuming your files are named Ind1.R1.fq.gz and Ind2.R2.fq.gz.

for R1 in *.R1.fastq.gz
do
  Name=${R1%.R1*}
  bwa mem Zosterops_genome.fsa -t 8 "${Name}.R1.fastq.gz"  "${Name}.R2.fastq.gz" -M | samtools view -q 20 -bS - | samtools sort -  $Name 
done

#Note: Again, if you want to submit one job for each alignment:
for R1 in *.R1.fastq.gz
do
  Name=${R1%.R1*}
  echo "bwa mem Zosterops_genome.fsa -t 8" "${Name}.R1.fastq.gz"  "${Name}.R2.fastq.gz" "-M | samtools view -q 20 -bS - | samtools sort -"  $Name >> command_file 
done

split -l1 command_file alignment.sh
for i in alignment.sh*
do qsub $i
done
# move all bam in bam_with_duplicates directory
mkdir bam_with_duplicates
mv *bam bam_with_duplicates

### Add read group and remove duplicates. Use bamaddrg from bamtools (Erik Garrison)

for bam in ./bam_with_duplicates/*bam
do
	Name=${bam%.bam}
	echo "./bamaddrg -b" $bam "-s" $Name "| ./samtools-0.1.19/samtools rmdup - " ${Name}_rmdup.bam >> command_file_rmdup
done
split -l1 command_file_rmdup rmdup.sh
for i in rmdup.sh*
do qsub $i
done

### Check a few statistics about an alignment (e.g. file1.bam):
samtools flagstat file1.bam

### For pooled datasets, production of a mpileup file is needed for analyses in R
samtools mpileup -B BO-BBH.rmdup.bam BO-GRY.rmdup.bam TE-BBH.rmdup.bam TE-GRY.rmdup.bam VO-BBH.rmdup.bam VO-GRY.rmdup.bam MO-BGH.rmdup.bam 3C-BGH.rmdup.bam BV-BBN.rmdup.bam CO-BBN.rmdup.bam ERM-BBH.rmdup.bam ES-BBH.rmdup.bam MA-BEL.rmdup.bam > All_13_pops.mpileup
### Sync of the files using a java sript from popoolation 2. Beware that mpileup files are really heavy (more than 200 Gb)
java -ea -Xmx12g -jar ./mpileup2sync.jar --input All_13_pops.mpileup --output All_13_pops.sync --fastq-type sanger --min-qual 20 --threads 8



### SNP calling using freeBayes (Erik Garrison)
## To speed up the process (for whole genome sequencing), it is recommended to run several small jobs on portions of the genome (-t option in freebayes).
## For this, bed files listing all scaffolds and regions to be covered 
## need to be provided. This can also be used to call SNPs only on a few regions of interests. 
## To get lengths of all the scaffolds in a reference fasta file file.fa, run:
awk '/^>/ {if (seqlen){print seqlen};print;seqtotal+=seqlen;seqlen=0;seq+=1;next;}
    {seqlen=seqlen+length($0)}
    END{print seqlen;print seq" sequences, total length " seqtotal+seqlen}' file.fa

## Then for each bed file (format: sequence_name	start_pos	end_pos):
## To list all bam files on one single line:
ls *bam | tr "\n" " " 
## This gives a list,e.g.: file1.bam file2.bam file3.bam
## Then copy and paste so you call SNPs on all bam files:

./freebayes -f Zosterops_genome.fsa file1.bam file2.bam file3.bam -t file_1.bed --genotype-qualities > SNPs_raw_1.vcf

### SNP filtering: this is only an example. Parameters should be adapted according to mean depth of coverage and number of missing genotypes. It is
### necessary to play a bit at this stage so you can have an idea of how confident you can be with your SNPs. Be careful that Z markers should be removed in
### first analyses.
vcftools --vcf SNPs_raw_1.vcf --minQ 20 --minGQ 30 --min-meanDP 10 --max-meanDP 35 --max-missing 0.7 --min-alleles 2 --max-alleles 3 --remove-indels --recode --recode-INFO-all --out SNPs_filtered_1.vcf
 
 
### Some packages (e.g. PopGenome) do not like MNPs or complex variants. It can be useful to have a vcf with only SNPs or MNPs
### divided into SNPs. Use the script in vcftools vcfallelicprimitives:
./vcfallelicprimitives SNPs_filtered_1.vcf > SNPs_splitted_1.vcf 


### To check for large deletions or verify that some SNPs do not fall in repetitive regions, it is useful to check the sequencing depth or the coverage.
### Use for that bedtools (http://bedtools.readthedocs.org/en/latest/). Again it is necessary to produce a bed file (-b) for the region of interest:
## This script gives the percentage of each feature in the bed file covered by at least one read (coverage)
coverageBed -abam file1.bam -b file_to_check_coverage.bed > file1_cov.out
## This script gives the number of reads at each position for each feature in the bed file (depth, option -d)
coverageBed -abam file1.bam -b file_to_check_coverage.bed -d > file1_depth.out

### Now you should have vcf file or mpileup data, that can be converted and used for analyses.


